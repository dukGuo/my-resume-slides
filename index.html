<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="log-player">
  <title>slides</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

  <link rel="stylesheet" href="dist/base.css">
    <style>
      .font-sans {
        font-family: 'Lato', 'SimHei', 'STHeiti', 'SimHei', 'Serif';
      }
    
      .font-serif {
        font-family: 'Source Serif Pro', 'Songti SC', 'SimSun', 'Serif', serif;
      }
      .audio-grid {
        display: grid;
        /* 两列布局 */
        grid-template-columns: repeat(2, 1fr);
        gap: 1rem;               /* 列之间的间距 */
        margin-top: 1rem;
        justify-items: center;   /* 每列内部水平居中 */
      }

      .audio-column {
        /* 列内部垂直排布：标题在上，音频在下 */
        display: flex;
        flex-direction: column;
        align-items: center;     /* 标题 & audio 都水平居中 */
        gap: 1.0rem;               /* 行之间的间距 */
      }

      .column-title {
        font-size: 1.0rem;
        font-weight: bold;
        /* 你还可以加下划线、边距等等装饰 */
      }

      /* 可选：统一所有 audio 的宽度，或者让它自适应列宽 */
      .audio-column audio {
        width: 300px;            /* 固定宽度 */
        /* width: 100%; max-width: 300px; */ /* 或者自适应＋上限 */
      }
    </style>
    <script>
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          processEscapes: true
        },
        options: {
          renderActions: {
            addMenu: [0, '', '']
          }
        }
      };
    </script>
    <script id="MathJax-script" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.1/es5/tex-chtml.min.js"></script>
    
    
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <link rel="stylesheet" href="dist/reveal.css">
    <link rel="stylesheet" href="dist/theme/simple.css" id="theme">

  <link rel="stylesheet" href="dist/jyy.css">
  <!-- <link rel="stylesheet" href="dist/reset.css">
  <link rel="stylesheet" href="dist/reveal.css">  -->
   <!-- <link href="https://fonts.font.im/css?family=Source+Serif+Pro%7CLato%7CInconsolata" rel="stylesheet" type="text/css"> -->

  <style>
    .float-right{float: right;}
    .float-left{float: left;}

    
    </style>
  <!-- <link rel="stylesheet" href="dist/theme/simple.css" id="theme"> -->
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">自我介绍</h1>

            <p style=" height: 300px;text-align: right;margin-top: 100px;padding-right: 60px;">
              郭大可 2025
            </p>
</section>

<section>
  <section id="" class="title-slide slide level1">
    <h1>个人信息</h1>

  </section>
  <section id="背景" class="slide level2">
    <h2>基本信息</h2>
    <ul>
    <li><strong>教育背景:</strong></li>
    <ul>
    <li>西北工业大学本硕,计算机科学与技术，导师：谢磊教授</li>
    </ul>
    <!-- <br> -->
    <li><strong>在校研究方向:</strong></li>
    <ul>
      <li>高表现力有声书合成（HiGNN-TTS、TACA-TTS）</li>
      <li>TTS野生语音数据处理（WenetSpeech4TTS）</li>
      <li>大型语音生成模型（VALL·E、单/多码本LMTTS）</li>
      <li>多人对话式语音合成（DialoSpeech）</li>
    </ul>
    <strong><li>实习经历:</strong></li>
    <ul>
    <li><strong>小红书 (2024.04–2024.07)：</strong></li>
    <ul>
      <li>E2E音乐合成：数据清洗、codec 重建对比及多码本模型适配。</li>
    </ul>
    <li><strong>阿里巴巴 (2024.09–至今)：</strong></li>
    <ul>
      <li>单码本 codec 对比研究</li>
      <li>流式语音 token 解码方案设计</li>
      <li>vocoder 泛化能力改进及流式推理适配</li>
      <li>自回归时长预测在 NAR TTS 中的应用研究</li>
      <!-- <li>上下文感知 ASR 基准测试框架搭建</li> -->
    </ul>
    </ul>
    </ul>
  </section> 
</section>
<section>
  <section id="audiobook" class="title-slide slide level1">
    <h1>表现力有声书合成</h1>

  </section>
  <section id="HiGNN-TTS" class="slide level2">
    <h2>HiGNN-TTS: 利用文本结构的表现力有声书合成</h2>
    <ul>
      <li>出发点：韵律表达与文本依存(韵律)结构相关 -> 如何高效利用文本信息？</li>

      <li>方法</li>
      <ul>
        <li>依存关系与韵律表达强相关 -> 句法依存图作为先验信息 -> GNN建模 </li>
        <li>层次化的韵律建模 -> 词/句/上下文 -> 虚拟全局节点+上下文 Attention</li>
        <li>利用文本语义信息 -> Bert Embedding 初始化图节点</li>
        <li>无监督学习效果差 -> 预训练的 Mel Encoder 做监督</li>
      </ul>
      <div style="display: flex; align-items: stretch; gap: 10px;">
        <img src="imgs/hignn/overview.jpg" style="height: 280pt; object-fit: cover;">
        <img src="imgs/hignn/gnn.jpg" style="height: 280pt; object-fit: cover;">
      </div>
      <!--  style="position:absolute;top:160px ;left: 520px;" -->
      <!-- <li>结构示意图</li> -->
    </ul>
  </section>
    <section id="Audio Samples" class="slide level2">
      <h2>HiGNN-TTS Results</h2>
      <div class="audio-grid">
        <!-- 第一列：一个整体容器，里头既有标题，也有两条 audio -->
        <div class="audio-column">
          <div class="column-title">FS2-BERT</div>
          <audio controls src="audios/hignn/FS2BERT/DB_19M_000033_0007.wav"></audio>
          <audio controls src="audios/hignn/FS2BERT/DB_26F_010041_0005.wav"></audio>
          <audio controls src="audios/hignn/FS2BERT/long1.wav"></audio>
          <audio controls src="audios/hignn/FS2BERT/long2.wav"></audio>
        </div>
      
        <!-- 第二列：同理 -->
        <div class="audio-column">
          <div class="column-title">HiGNN-TTS</div>
          <audio controls src="audios/hignn/HiGNN-TTS/DB_19M_000033_0007.wav"></audio>
          <audio controls src="audios/hignn/HiGNN-TTS/DB_26F_010041_0005.wav"></audio>
          <audio controls src="audios/hignn/HiGNN-TTS/long1.wav"></audio>
          <audio controls src="audios/hignn/HiGNN-TTS/long2.wav"></audio>
        </div>
      </div>

    </section>
  <section id="TACA" class="slide level2">
    <h2>TACA-TTS: 从大量野生数据中建模"文本->风格"映射</h2>
    <ul>
      <li>出发点: 当 AM 和数据固定时，TTS 的表现力上限取决于风格表征的好坏</li>
      <li>方法： </li>

      <ul>
        <li>AM 对数据质量要求高，联合训练风格表征存在局限性-> 将风格建模从声学模型中解耦，多阶段训练(风格空间构建->"文本-风格"映射->声学模型联调)</li>
        <li>少量有标注数据+大量无监督数据+对比学习 -> 完备的风格空间</li>
        <li>大量文本音频对+对比学习+cos loss -> "文本-风格"映射</li>
        <li>设计context encoder 从文本中编码风格表征，在两种主流声学模型(Vits,LM)上验证有效性</li>
      </ul>
      <div style="display: flex; align-items: stretch; gap: 10px;">
        <img src="imgs/taca/overview.jpg" style="height: 195pt; object-fit: cover;">
        <img src="imgs/taca/context.jpg" style="height: 170pt; object-fit: cover;">
      </div>
    </ul>
  </section>
  <section id="TACA" class="slide level2">
    <h2>TACA-TTS: 从大量野生数据中建模"文本->风格"映射</h2>
    <ul>
      <li>对比学习正负样例构建：</li>
      <blockquote>
        <p>风格空间构建：</p>
        <ul>
          <li>同一句的不同切片→正样例</li>
          <li>同一类别的不同音频切片→正样例</li>
        </ul>
        <p>文本-风格映射：</p>
        <ul>
          <li>音频风格表征间相似度，大于α→正样例，小于β→负样例</li>
        </ul>
      </blockquote>
      <li> 声学模型设计：</li>

       <div style="display: flex; align-items: stretch; gap: 10px;">
        <img src="imgs/taca/vits.jpg" style="height: 190pt; object-fit: cover;">
        <img src="imgs/taca/lm.jpg" style="height: 190pt; object-fit: cover;">
      </div>
    </ul>

  </section>
  <section id="TACA" class="slide level2">
    <h2>TACA-TTS Results</h2>
    
  <div class="audio-grid">
    <!-- 第一列：一个整体容器，里头既有标题，也有两条 audio -->
    <div class="audio-column">
      <div class="column-title">VITS</div>
      <audio controls src="audios/taca/VITS/text_1.wav"></audio>
      <audio controls src="audios/taca/VITS/text_5.wav"></audio>
    </div>
  
    <!-- 第二列：同理 -->
    <div class="audio-column">
      <div class="column-title">TACA-VITS</div>
      <audio controls src="audios/taca/TACA-VITS/text_1.wav"></audio>
      <audio controls src="audios/taca/TACA-VITS/text_5.wav"></audio>
    </div>
  </div>

    <br>
  <div class="audio-grid">
    <!-- 第一列：一个整体容器，里头既有标题，也有两条 audio -->
    <div class="audio-column">
      <div class="column-title">LM</div>
      <audio controls src="audios/taca/LM/text_1.wav"></audio>
      <audio controls src="audios/taca/LM/text_5.wav"></audio>
    </div>
  
    <!-- 第二列：同理 -->
    <div class="audio-column">
      <div class="column-title">TACA-LM</div>
      <audio controls src="audios/taca/TACA-LM/text_6.wav"></audio>
      <audio controls src="audios/taca/TACA-LM/text_6.wav"></audio>
    </div>
  </div>
  
  
  </section>

</section>
<section>
  <section id="stream" class="title-slide slide level1">
    <h1>流式语音生成</h1>
  
  </section>
<section id="Stream" class="slide level2">
  <h2>StreamFlow：Flow-matching流式解码方案</h2>
  <ul>
    <li>出发点: ASR token提升了LM的性，但后端解码依赖Flow-matching -> 难以满足实时性要求</li>
    <li>方法： </li>
    <ul>
        <li>架构调整: <del>UNet+Transfomer</del> -> DiTs (利于模型感受野控制) </li>
        <li>流式 != causal != AR, 流式模型可以拥有未来感受野</li>
        <li>临近token -> block, 以 block 为基本单元通过mask控制感受野</li>
    </ul>
  <div style="display: flex; align-items: center; justify-content: center; gap: 10px;">
    <img src="imgs/streamfm/overview.jpg" style="height: 280pt; object-fit: cover;">
    <img src="imgs/streamfm/infer.jpg" style="height: 90pt; object-fit: cover;">
  </div>
  </ul>
</section>
<section id="Stream" class="slide level2">
  <h2>StreamFlow：Flow-matching流式解码方案</h2>
  <ul>
    <div style="display: flex; align-items: center; justify-content: center; gap: 10px;">
      <img src="imgs/streamfm/mask.jpg" style="height: 140pt; object-fit: cover;">
      <img src="imgs/streamfm/dit.jpg" style="height: 130pt; object-fit: cover;">
    </div>
    <li>三种典型mask：</li>
    <ul>
      <li>Block Mask: block内可见，不改变感受野 </li>
      <li>Backward Mask: 可见历史 block，将感受野向历史扩张 </li>
      <li>Forward Mask: 可见未来 block 将感受野向未来扩张 </li>
    </ul>
    <li>三种mask在DiT block中自由分配，可以精确的控制模型整体可见范围（类似卷积）</li>
    <blockquote>Token2wav 是比较local，对全局感受野的需求不大</blockquote>
  </ul>
</section>
<section id="Stream" class="slide level2">
  <h2>StreamFlow Results</h2>
  <!-- <ul><p>Speed</p></ul> -->
    <div class="audio-grid">
      <!-- 第一列：一个整体容器，里头既有标题，也有两条 audio -->
      <div class="audio-column">
        <div class="column-title">Non-Streaming</div>
        <audio controls src="audios/stream/samples/DiT-CV(Non-Streaming)/0.wav"></audio>
        <audio controls src="audios/stream/samples/DiT-CV(Non-Streaming)/2.wav"></audio>
        <!-- <audio controls src="audios/stream/samples/DiT-CV(Non-Streaming)/2.wav"></audio> -->
        <audio controls src="audios/stream/samples/DiT-CV(Non-Streaming)/5.wav"></audio>
      </div>
    
      <!-- 第二列：同理 -->
      <div class="audio-column">
        <div class="column-title">Streaming</div>
        <audio controls src="audios/stream/samples/StreamFlow-LR/0.wav"></audio>
        <audio controls src="audios/stream/samples/StreamFlow-LR/2.wav"></audio>
        <!-- <audio controls src="audios/stream/samples/DiT-CV(Non-Streaming)/2.wav"></audio> -->
        <audio controls src="audios/stream/samples/StreamFlow-LR/5.wav"></audio>
      </div>
    </div>
   <br> 
  <div style="display: flex; align-items: center; justify-content: center; gap: 10px;">
    <!-- <img src="imgs/streamfm/mask.jpg" style="height: 140pt; object-fit: cover;"> -->
    <img src="imgs/streamfm/speed.png" style="height: 180pt; object-fit: cover;">
  </div>
</section>

<section id="vocoder" class="slide level2">
  <h2>Vocoder 流式适配</h2>
   <ul>
    <li> 现有问题：</li>
    <ul>
      <li>现有BigVGAN未来感受野过大，首包留存率过低 (时延)</li>
      <li>通过Overlap + Fade-in & Fade-out可以缩减感受野，但会引入由相位冲突导致的爆破音 (流式)</li>
      <li>Causal-BigVGAN 音质下降严重 (音质)</ul>
    </ul>
    <br>
    <ul><p><strong>Trade-off:</strong> 在维持较高的首包留存率的前提下，如何提升流式生成的音质？🧐</p>
    <ul>
      <li>混合Causal卷积与正常卷积! 构造不对称感受野 </li>
      <li>底层ResBlock -> 替换为Causal，通过3*1卷积补偿感受野</li>
      <li>高层ResBlock -> 缩减dilation，压缩感受野</li>
      <li>转置卷积保持不变（Causal化后音质下降）</li>
    </ul>
    </ul>
    <ul>
    <li>结果：</li>
    <ul>
      <li>感受野（帧）：33+33 -> 51+11</li>
      <li>首包留存率（40帧）：0.175 -> 0.725</li>
      <li>音质（PESQ）：3.89 -> 3.81</li>
    </ul>
    </ul>
   </ul>

</section>
</section>

<section>
  <section id="flexspeech" class="title-slide slide level1">
    <h1>FlexSpeech</h1>

  </section>
  <section id="flexspeech" class="slide level2">
    <h2>FlexSpeech: AR与NAR相结合的尝试</h2>
    <ul>
      <li>出发点：AR更擅长韵律表达，NAR有更好地稳定性、可控性，如何结合二者的优势？</li>
      <li>方法：</li>
      <ul>
        <li>音素建模，DiT为主干网络，Flow-matching还原为mel</li>
        <li>Encoder-Decoder结构预测离散化时长，Encoder加入mlm建模，提升语义理解能力，Decoder自回归预测</li>
        
      </ul>
      <div style="display: flex; align-items: center; justify-content: center; gap: 10px;">
        <!-- <img src="imgs/streamfm/mask.jpg" style="height: 140pt; object-fit: cover;"> -->
        <img src="imgs/flex/overview.jpg" style="height: 290pt; object-fit: cover;">
      </div>
    </ul>
  </section>
  <section id="flexspeech" class="slide level2">
    <h2>FlexSpeech: AR与NAR相结合的尝试</h2>
    <ul>
      <li>韵律风格不好 != 时长模型预测差，时长模型预测的时长不符合主观偏好</li>
      <li>通过DPO实现偏好优化。sft loss维持知识，只在差异时长上计算dpo loss</li>
    
      <ul>
        <li>少量人工标注偏好数据 -> 提高稳定性&主观听感 </li>
        <li>少量风格偏好数据 -> 快速风格迁移</li>
      </ul>
      <div style="display: flex; align-items: center; justify-content: center; gap: 10px;">
        <!-- <img src="imgs/streamfm/mask.jpg" style="height: 140pt; object-fit: cover;"> -->
        <img src="imgs/flex/dpo.jpg" style="height: 290pt; object-fit: cover;">
      </div>
    </ul>
  </section>


    <section id="flexspeech" class="slide level2">
    <h2>FlexSpeech Results</h2>
    <ul>
      <p>零样本克隆</p>
    </ul>
  <div class="audio-grid">
    <!-- 第一列：一个整体容器，里头既有标题，也有两条 audio -->
    <div class="audio-column">
      <div class="column-title">Reference</div>
      <audio controls src="audios/flex/comparison/ref/en_2.wav"></audio>

      <audio controls src="audios/flex/comparison/ref/mega3_trump.wav"></audio>
      <audio controls src="audios/flex/comparison/ref/moqianxue_37.wav"></audio>
      <audio controls src="audios/flex/comparison/ref/gct_dingzhen.wav"></audio>
    
    </div>
  
    <!-- 第二列：同理 -->
    <div class="audio-column">
      <div class="column-title">FlexSpeech</div>
      <audio controls src="audios/flex/comparison/zeroshot_demo/en_2-testclean_7127_75947_0016.wav"></audio>
      <audio controls src="audios/flex/comparison/zeroshot_demo/mega3_trump-seed_23176029.wav"></audio>
      <audio controls src="audios/flex/comparison/zeroshot_demo/moqianxue_37-other004.wav"></audio>
      <audio controls src="audios/flex/comparison/zeroshot_demo/gct_dingzhen-other079.wav"></audio>
    </div>
  </div>
  <br>
  <ul>
      <p style="display:inline-block; margin:0; vertical-align:middle;">
        风格迁移
      </p>
      <audio controls src="audios/flex/styletransfer/stype_prompt/e85s028.wav"
        style="vertical-align:middle; margin-left:0.5em;"></audio>  </ul>
  <div class="audio-grid">
    <!-- 第一列：一个整体容器，里头既有标题，也有两条 audio -->
    <div class="audio-column">
      <div class="column-title">Reference</div>
      <audio controls src="audios/flex/styletransfer/speaker/eo_female.wav"></audio>
      <audio controls src="audios/flex/styletransfer/speaker/y132.wav"></audio>
    </div>
  
    <!-- 第二列：同理 -->
    <div class="audio-column">
      <div class="column-title">Results</div>
      <audio controls src="audios/flex/styletransfer/res/eo_female_e85s028-e106s158_7.wav"></audio>
      <audio controls src="audios/flex/styletransfer/res/y132_e87s127-e133s109_6.wav"></audio>
    </div>
  </div>

      </section>
</section>
<section id="title-slide">
  <h1 class="title">Thanks! </h1>

  <!-- <p style=" height: 300px;text-align: right;margin-top: 100px;padding-right: 60px;">
    郭大可 2025
  </p> -->
</section>
    </div>
  </div>



  <!-- reveal.js plugins -->
````<script src="dist/reveal.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
  <link rel="stylesheet" href="plugin/highlight/style.css">
  <script src="plugin/highlight/highlight.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      // Reveal.initialize({
      //   // Display controls in the bottom right corner
      //   controls: true,

      //   // Help the user learn the controls by providing hints, for example by
      //   // bouncing the down arrow when they first encounter a vertical slide
      //   controlsTutorial: true,

      //   // Determines where controls appear, "edges" or "bottom-right"
      //   controlsLayout: 'bottom-right',

      //   // Visibility rule for backwards navigation arrows; "faded", "hidden"
      //   // or "visible"
      //   controlsBackArrows: 'faded',

      //   // Display a presentation progress bar
      //   progress: true,

      //   // Display the page number of the current slide
      //   slideNumber: false,

      //   // 'all', 'print', or 'speaker'
      //   showSlideNumber: 'all',

      //   // Add the current slide number to the URL hash so that reloading the
      //   // page/copying the URL will return you to the same slide
      //   hash: true,

      //   // Start with 1 for the hash rather than 0
      //   hashOneBasedIndex: false,

      //   // Flags if we should monitor the hash and change slides accordingly
      //   respondToHashChanges: true,

      //   // Push each slide change to the browser history
      //   history: false,

      //   // Enable keyboard shortcuts for navigation
      //   keyboard: true,

      //   // Enable the slide overview mode
      //   overview: true,

      //   // Disables the default reveal.js slide layout (scaling and centering)
      //   // so that you can use custom CSS layout
      //   disableLayout: false,

      //   // Vertical centering of slides
      //   center: true,

      //   // Enables touch navigation on devices with touch input
      //   touch: true,

      //   // Loop the presentation
      //   loop: false,

      //   // Change the presentation direction to be RTL
      //   rtl: false,

      //   // see https://revealjs.com/vertical-slides/#navigation-mode
      //   navigationMode: 'default',

      //   // Randomizes the order of slides each time the presentation loads
      //   shuffle: false,

      //   // Turns fragments on and off globally
      //   fragments: true,

      //   // Flags whether to include the current fragment in the URL,
      //   // so that reloading brings you to the same fragment position
      //   fragmentInURL: true,

      //   // Flags if the presentation is running in an embedded mode,
      //   // i.e. contained within a limited portion of the screen
      //   embedded: false,

      //   // Flags if we should show a help overlay when the questionmark
      //   // key is pressed
      //   help: true,

      //   // Flags if it should be possible to pause the presentation (blackout)
      //   pause: true,

      //   // Flags if speaker notes should be visible to all viewers
      //   showNotes: false,

      //   // Global override for autoplaying embedded media (null/true/false)
      //   autoPlayMedia: null,

      //   // Global override for preloading lazy-loaded iframes (null/true/false)
      //   preloadIframes: null,

      //   // Number of milliseconds between automatically proceeding to the
      //   // next slide, disabled when set to 0, this value can be overwritten
      //   // by using a data-autoslide attribute on your slides
      //   autoSlide: 0,

      //   // Stop auto-sliding after user input
      //   autoSlideStoppable: true,

      //   // Use this method for navigation when auto-sliding
      //   autoSlideMethod: null,

      //   // Specify the average time in seconds that you think you will spend
      //   // presenting each slide. This is used to show a pacing timer in the
      //   // speaker view
      //   defaultTiming: null,

      //   // Enable slide navigation via mouse wheel
      //   mouseWheel: false,

      //   // The display mode that will be used to show slides
      //   display: 'block',

      //   // Hide cursor if inactive
      //   hideInactiveCursor: true,

      //   // Time before the cursor is hidden (in ms)
      //   hideCursorTime: 5000,

      //   // Opens links in an iframe preview overlay
      //   previewLinks: false,

      //   // Transition style (none/fade/slide/convex/concave/zoom)
      //   transition: 'slide',

      //   // Transition speed (default/fast/slow)
      //   transitionSpeed: 'default',

      //   // Transition style for full page slide backgrounds
      //   // (none/fade/slide/convex/concave/zoom)
      //   backgroundTransition: 'fade',

      //   // Number of slides away from the current that are visible
      //   viewDistance: 3,

      //   // Number of slides away from the current that are visible on mobile
      //   // devices. It is advisable to set this to a lower number than
      //   // viewDistance in order to save resources.
      //   mobileViewDistance: 2,

      //   // reveal.js plugins
      //   plugins: [
      //     RevealNotes,
      //     RevealSearch,
      //     RevealZoom
      //   ]
      // });
      Reveal.initialize({

          width: 1024, height: 768,
          plugins: [ RevealMarkdown, RevealHighlight],
          slideNumber: 'c/t',
          controlsTutorial: true,
          progress: false,
          hash: true,
          center: false,
          autoAnimateUnmatched: true,
          autoAnimateEasing: 'ease-out',
          autoAnimateDuration: 0.3,
          transitionSpeed: 'fast',
          dependencies: [
            { src: 'plugin/markdown/marked.js', condition: function () { return !!document.querySelector('[data-markdown]'); } },
            { src: 'plugin/markdown/markdown.js', condition: function () { return !!document.querySelector('[data-markdown]'); } },
            { src: 'plugin/highlight/highlight.js', async: true },
          ]
        });
    </script>
    </body>
</html>
